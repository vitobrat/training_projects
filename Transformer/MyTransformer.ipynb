{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42dbc4e7-b6c1-403d-abf5-95c89546cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97efbf32-4c05-4c4a-afbc-7ed1f941daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, vector_dimension, num_heads):\n",
    "        super().__init__()\n",
    "        assert vector_dimension % num_heads == 0, \"vector_dimension must be divisible by num_heads\"\n",
    "\n",
    "        self.vector_dimension = vector_dimension\n",
    "        self.num_heads = num_heads\n",
    "        self.dimention_each_head = vector_dimension // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(vector_dimension, vector_dimension)\n",
    "        self.W_k = nn.Linear(vector_dimension, vector_dimension)\n",
    "        self.W_v = nn.Linear(vector_dimension, vector_dimension)\n",
    "        self.W_o = nn.Linear(vector_dimension, vector_dimension)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, vector_dimension = x.size()\n",
    "        return x.view(batch_size, self.num_heads, seq_len, self.dimention_each_head)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.dimention_each_head)\n",
    "        if mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
    "        attention_probs = torch.softmax(attention_scores, dim=-1)\n",
    "        output = torch.matmul(attention_probs, V)\n",
    "        return output\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_len, _ = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_len, self.vector_dimension)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_q(K))\n",
    "        V = self.split_heads(self.W_q(V))\n",
    "\n",
    "        attention_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attention_output))\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd4b8e85-b64d-4cec-b4f1-877fc59b4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, vector_dimention, latent_dimention):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(vector_dimention, latent_dimention)\n",
    "        self.linear2 = nn.Linear(latent_dimention, vector_dimention)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.linear1(x)\n",
    "        output = self.activation(output)\n",
    "        output = self.linear2(output)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "200db5dd-ac40-4e8d-81cc-6bc73bea4cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEncoding(nn.Module):\n",
    "    def __init__(self, vector_dimention, max_seq_len):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_seq_len, vector_dimention)\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, vector_dimention, 2).float() * (-(math.log(10000.0) / vector_dimention)))\n",
    "\n",
    "        pe[:, ::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, : x.size(1)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ce5593-8230-4557-8579-30caff01dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vector_dimention, num_heads, latent_dimention, dropout):\n",
    "        super().__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(vector_dimention, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(vector_dimention, latent_dimention)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(vector_dimention)\n",
    "        self.norm2 = nn.LayerNorm(vector_dimention)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        output_attention = self.multi_head_attention(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(output_attention))\n",
    "        output_ff = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(output_ff))\n",
    "        return x     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21f7662-86c6-4629-bdec-9c83d1337d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vector_dimention, num_heads, latent_dimention, dropout):\n",
    "        super().__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(vector_dimention, num_heads)\n",
    "        self.multi_head_cross_attention = MultiHeadAttention(vector_dimention, num_heads) \n",
    "        self.feed_forward = PositionWiseFeedForward(vector_dimention, latent_dimention)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(vector_dimention)\n",
    "        self.norm2 = nn.LayerNorm(vector_dimention)\n",
    "        self.norm3 = nn.LayerNorm(vector_dimention)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encode_output, trg_mask, src_mask):\n",
    "        output_self_attention = self.multi_head_attention(x, x, x, trg_mask)\n",
    "        x = self.norm1(x + self.dropout(output_self_attention))\n",
    "        \n",
    "        output_cross_attention = self.multi_head_cross_attention(x, encode_output, encode_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(output_cross_attention))\n",
    "        \n",
    "        output_ff = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(output_ff))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e0cff24-fa9d-4e19-9db1-2357f6d7e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, vector_dimention, num_heads, num_layers, latent_dimention, max_seq_len, dropout):\n",
    "        super().__init__()\n",
    "        self.position_encoder = PositionEncoding(vector_dimention, max_seq_len)\n",
    "        self.encoder_embeddings = nn.Embedding(src_vocab_size, vector_dimention)\n",
    "        self.decoder_embeddings = nn.Embedding(trg_vocab_size, vector_dimention)\n",
    "        \n",
    "        self.encoder_layers = nn.ModuleList([Encoder(vector_dimention, num_heads, latent_dimention, dropout) for _ in range(0, num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([Decoder(vector_dimention, num_heads, latent_dimention, dropout) for _ in range(0, num_layers)])\n",
    "\n",
    "        self.linear_final = nn.Linear(vector_dimention, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, trg):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        trg_mask = (trg != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = trg.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        trg_mask = trg_mask & nopeak_mask\n",
    "        return src_mask.to(device), trg_mask.to(device)\n",
    "    \n",
    "    def forward(self, input_embedding, target_embedding):\n",
    "        pos_input_emb = self.dropout(self.position_encoder(self.encoder_embeddings(input_embedding)))\n",
    "        pos_trg_emb = self.dropout(self.position_encoder(self.encoder_embeddings(target_embedding)))\n",
    "\n",
    "        src_mask, trg_mask = self.generate_mask(input_embedding, target_embedding)\n",
    "\n",
    "        encod_output = pos_input_emb\n",
    "        for encod_layer in self.encoder_layers:\n",
    "            encod_output = encod_layer(encod_output, src_mask)\n",
    "\n",
    "        decod_output = pos_trg_emb\n",
    "        for decod_layer in self.decoder_layers:\n",
    "            decod_output = decod_layer(decod_output, encod_output, trg_mask, src_mask)\n",
    "\n",
    "        output = self.linear_final(decod_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7979b36a-5705-47e3-bc00-a7798aefb81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51878185-b7a7-4aae-8704-b0deb3ee81b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = 5000\n",
    "trg_vocab_size = 5000\n",
    "vector_dimention = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "latent_dimention = 2048\n",
    "max_seq_length = 100\n",
    "dropout = 0.25\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "transformer = Transformer(src_vocab_size, trg_vocab_size, vector_dimention, num_heads, num_layers, latent_dimention, max_seq_length, dropout).to(device)\n",
    "\n",
    "# Generate random sample data\n",
    "src_data = torch.randint(1, src_vocab_size, (batch_size, max_seq_length)).to(device)  # (batch_size, seq_length)\n",
    "trg_data = torch.randint(1, trg_vocab_size, (batch_size, max_seq_length)).to(device)  # (batch_size, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54940142-9d26-441b-b5b9-302e6ed6f564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 8.680929183959961\n",
      "Epoch: 2, Loss: 8.23397159576416\n",
      "Epoch: 3, Loss: 7.727494239807129\n",
      "Epoch: 4, Loss: 7.244029521942139\n",
      "Epoch: 5, Loss: 6.978521347045898\n",
      "Epoch: 6, Loss: 6.529621124267578\n",
      "Epoch: 7, Loss: 6.010624885559082\n",
      "Epoch: 8, Loss: 5.696918964385986\n",
      "Epoch: 9, Loss: 5.446065425872803\n",
      "Epoch: 10, Loss: 5.271342754364014\n",
      "Epoch: 11, Loss: 5.129522323608398\n",
      "Epoch: 12, Loss: 5.26650333404541\n",
      "Epoch: 13, Loss: 5.7097673416137695\n",
      "Epoch: 14, Loss: 5.9030890464782715\n",
      "Epoch: 15, Loss: 5.882598400115967\n",
      "Epoch: 16, Loss: 6.7095842361450195\n",
      "Epoch: 17, Loss: 6.675469875335693\n",
      "Epoch: 18, Loss: 6.799657344818115\n",
      "Epoch: 19, Loss: 7.327692985534668\n",
      "Epoch: 20, Loss: 7.554989814758301\n",
      "Epoch: 21, Loss: 7.484623432159424\n",
      "Epoch: 22, Loss: 7.351357936859131\n",
      "Epoch: 23, Loss: 7.322887897491455\n",
      "Epoch: 24, Loss: 7.3069748878479\n",
      "Epoch: 25, Loss: 7.314591884613037\n",
      "Epoch: 26, Loss: 7.387606143951416\n",
      "Epoch: 27, Loss: 7.465312957763672\n",
      "Epoch: 28, Loss: 7.413875102996826\n",
      "Epoch: 29, Loss: 7.192042350769043\n",
      "Epoch: 30, Loss: 6.9808197021484375\n",
      "Epoch: 31, Loss: 7.0614800453186035\n",
      "Epoch: 32, Loss: 7.167791843414307\n",
      "Epoch: 33, Loss: 7.190108299255371\n",
      "Epoch: 34, Loss: 7.1335673332214355\n",
      "Epoch: 35, Loss: 7.09359073638916\n",
      "Epoch: 36, Loss: 7.041239261627197\n",
      "Epoch: 37, Loss: 6.9605631828308105\n",
      "Epoch: 38, Loss: 6.71933650970459\n",
      "Epoch: 39, Loss: 7.048067569732666\n",
      "Epoch: 40, Loss: 7.371189117431641\n",
      "Epoch: 41, Loss: 7.517146110534668\n",
      "Epoch: 42, Loss: 7.582902908325195\n",
      "Epoch: 43, Loss: 7.594523906707764\n",
      "Epoch: 44, Loss: 7.560465335845947\n",
      "Epoch: 45, Loss: 7.5378336906433105\n",
      "Epoch: 46, Loss: 7.474170207977295\n",
      "Epoch: 47, Loss: 7.36116361618042\n",
      "Epoch: 48, Loss: 7.345042705535889\n",
      "Epoch: 49, Loss: 7.436750888824463\n",
      "Epoch: 50, Loss: 7.5423431396484375\n",
      "Epoch: 51, Loss: 7.5508575439453125\n",
      "Epoch: 52, Loss: 7.573398113250732\n",
      "Epoch: 53, Loss: 7.532181739807129\n",
      "Epoch: 54, Loss: 7.586636066436768\n",
      "Epoch: 55, Loss: 7.632488250732422\n",
      "Epoch: 56, Loss: 7.644367218017578\n",
      "Epoch: 57, Loss: 7.5680413246154785\n",
      "Epoch: 58, Loss: 7.543445110321045\n",
      "Epoch: 59, Loss: 7.541121006011963\n",
      "Epoch: 60, Loss: 7.66946268081665\n",
      "Epoch: 61, Loss: 7.968195915222168\n",
      "Epoch: 62, Loss: 8.23874568939209\n",
      "Epoch: 63, Loss: 8.297574043273926\n",
      "Epoch: 64, Loss: 8.1142578125\n",
      "Epoch: 65, Loss: 7.86690092086792\n",
      "Epoch: 66, Loss: 7.728311061859131\n",
      "Epoch: 67, Loss: 7.596186637878418\n",
      "Epoch: 68, Loss: 7.524908065795898\n",
      "Epoch: 69, Loss: 7.492173194885254\n",
      "Epoch: 70, Loss: 7.424535274505615\n",
      "Epoch: 71, Loss: 7.360382556915283\n",
      "Epoch: 72, Loss: 7.285984039306641\n",
      "Epoch: 73, Loss: 7.261111259460449\n",
      "Epoch: 74, Loss: 7.29282808303833\n",
      "Epoch: 75, Loss: 7.292672634124756\n",
      "Epoch: 76, Loss: 7.285037994384766\n",
      "Epoch: 77, Loss: 7.3436126708984375\n",
      "Epoch: 78, Loss: 7.387979030609131\n",
      "Epoch: 79, Loss: 7.401430606842041\n",
      "Epoch: 80, Loss: 7.383136749267578\n",
      "Epoch: 81, Loss: 7.433614253997803\n",
      "Epoch: 82, Loss: 7.469832420349121\n",
      "Epoch: 83, Loss: 7.522456169128418\n",
      "Epoch: 84, Loss: 7.700706958770752\n",
      "Epoch: 85, Loss: 7.876626491546631\n",
      "Epoch: 86, Loss: 8.12044620513916\n",
      "Epoch: 87, Loss: 8.306950569152832\n",
      "Epoch: 88, Loss: 8.431736946105957\n",
      "Epoch: 89, Loss: 8.429658889770508\n",
      "Epoch: 90, Loss: 8.443765640258789\n",
      "Epoch: 91, Loss: 8.357854843139648\n",
      "Epoch: 92, Loss: 8.286730766296387\n",
      "Epoch: 93, Loss: 8.193599700927734\n",
      "Epoch: 94, Loss: 8.19043254852295\n",
      "Epoch: 95, Loss: 8.267061233520508\n",
      "Epoch: 96, Loss: 8.310516357421875\n",
      "Epoch: 97, Loss: 8.363770484924316\n",
      "Epoch: 98, Loss: 8.397957801818848\n",
      "Epoch: 99, Loss: 8.472521781921387\n",
      "Epoch: 100, Loss: 8.448867797851562\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9, 0.99), eps=1e-9)\n",
    "transformer.train()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    criterion.zero_grad()\n",
    "    predicts = transformer(src_data, trg_data[:, :-1])\n",
    "    loss = criterion(predicts.contiguous().view(-1, trg_vocab_size), trg_data[:, 1:].contiguous().view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084be93e-c4e9-43b3-8375-1e19a42ebef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
